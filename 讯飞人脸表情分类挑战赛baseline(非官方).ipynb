{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 讯飞人脸表情分类挑战赛baseline(非官方)\n",
    "\n",
    "\n",
    "> 一、赛事背景\n",
    "人脸表情是传播人类情感信息与协调人际关系的重要方式，表情识别是指从静态照片或视频序列中选择出表情状态，从而确定对人物的情绪与心理变化。在日常生活中人类习惯从面部表情中吸收非言语暗示，那么计算机可以完成类似任务吗？答案是肯定的，但是需要训练它学会识别情绪。\n",
    "\n",
    "\n",
    "> 二、赛事任务\n",
    "给定人脸照片完成具体的情绪识别，选手需要根据训练集数据构建情绪识别任务，并对测试集图像进行预测，识别人脸的7种情绪。\n",
    "\n",
    "> 三、评审规则\n",
    "1. 数据说明\n",
    "赛题数据由训练集和测试集组成，训练集数据集按照不同情绪的文件夹进行存放。其中：\n",
    "\n",
    "训练集：2.8W张人脸图像；\n",
    "\n",
    "测试集：7K张人脸图像；\n",
    "\n",
    "为了简化任务赛题图像只包含单张人脸，所有图像的尺寸为48 * 48像素。数据集包括的情绪标签包括以下7类：\n",
    "\n",
    "angry\n",
    "\n",
    "disgusted\n",
    "\n",
    "fearful\n",
    "\n",
    "happy\n",
    "\n",
    "neutral\n",
    "\n",
    "sad\n",
    "\n",
    "surprised\n",
    "\n",
    "\n",
    "> 四、基线分数\n",
    "\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/d7dda6d25bc24f75a30aa54bacc82cbea72a90aa5d7b4529b96cbbcd1f975178)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 数据解压\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cd 'data/data100817' && unzip -q Datawhale.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 数据集前处理\n",
    "\n",
    "\n",
    "对数据集进行处理，生成数据集信息，train.csv里包含图像的名称及其对应的标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import json\r\n",
    "import cv2\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "rootDir = 'data/data100817/Datawhale/train'\r\n",
    "\r\n",
    "image_id = []\r\n",
    "category_id = []\r\n",
    "\r\n",
    "def Test1(rootDir):\r\n",
    "    list_dirs = os.walk(rootDir)\r\n",
    "\r\n",
    "    img_id = 0\r\n",
    "    for root, dirs, files in list_dirs:\r\n",
    "        for d in dirs:\r\n",
    "\r\n",
    "            path = os.path.join(root, d)\r\n",
    "            cat_id = int(d)\r\n",
    "            for im in os.listdir(path):\r\n",
    "              \r\n",
    "                image_id.append(d + '/' + im)\r\n",
    "                category_id.append(cat_id)\r\n",
    "\r\n",
    "Test1(rootDir)\r\n",
    "\r\n",
    "\r\n",
    "img = pd.DataFrame(image_id)\r\n",
    "img = img.rename(columns = {0:\"image\"})\r\n",
    "img['label'] = category_id\r\n",
    "\r\n",
    "img.to_csv('work/train.csv', index=False)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 解题思路\n",
    "\n",
    "\n",
    "通过观察数据集，发现有一个类别特别少，一个类别特别多。所以使用labelshuffling方法作为一个基本的解题思路。另外，由于人脸带有较大的相似性，故使用了带有注意力机制的骨干网络，SE_ResNeXt50。\n",
    "\n",
    "\n",
    "* **知识点：labelshuffling**\n",
    "\n",
    "首先对原始的图像列表，按照标签顺序进行排序； 然后计算每个类别的样本数量，并得到样本最多的那个类别的样本数。 根据这个最多的样本数，对每类都产生一个随机排列的列表； 然后用每个类别的列表中的数对各自类别的样本数求余，得到一个索引值，从该类的图像中提取图像，生成该类的图像随机列表； 然后把所有类别的随机列表连在一起，做个Random Shuffling，得到最后的图像列表，用这个列表进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 导入所需要的库\r\n",
    "from sklearn.utils import shuffle\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from PIL import Image\r\n",
    "\r\n",
    "import paddle\r\n",
    "import paddle.nn as nn\r\n",
    "from paddle.io import Dataset\r\n",
    "import paddle.vision.transforms as T\r\n",
    "import paddle.nn.functional as F\r\n",
    "from paddle.metric import Accuracy\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")\r\n",
    "\r\n",
    "# labelshuffling\r\n",
    "\r\n",
    "def labelShuffling(dataFrame, groupByName = 'label'):\r\n",
    "\r\n",
    "    groupDataFrame = dataFrame.groupby(by=[groupByName])\r\n",
    "    labels = groupDataFrame.size()\r\n",
    "    print(\"length of label is \", len(labels))\r\n",
    "    maxNum = max(labels)\r\n",
    "    lst = pd.DataFrame()\r\n",
    "    for i in range(len(labels)):\r\n",
    "        print(\"Processing label  :\", i)\r\n",
    "        tmpGroupBy = groupDataFrame.get_group(i)\r\n",
    "        createdShuffleLabels = np.random.permutation(np.array(range(maxNum))) % labels[i]\r\n",
    "        print(\"Num of the label is : \", labels[i])\r\n",
    "        lst=lst.append(tmpGroupBy.iloc[createdShuffleLabels], ignore_index=True)\r\n",
    "        print(\"Done\")\r\n",
    "    # lst.to_csv('test1.csv', index=False)\r\n",
    "    return lst\r\n",
    "\r\n",
    "# 读取数据\r\n",
    "train_images = pd.read_csv('work/train.csv')\r\n",
    "train_images = labelShuffling(train_images)\r\n",
    "train_images = shuffle(train_images)\r\n",
    "# 划分训练集和校验集\r\n",
    "all_size = len(train_images)\r\n",
    "# print(all_size)\r\n",
    "train_size = int(all_size * 0.85)\r\n",
    "train_image_list = train_images[:train_size]\r\n",
    "val_image_list = train_images[train_size:]\r\n",
    "df = train_image_list\r\n",
    "# df = shuffle(df)\r\n",
    "train_image_path_list = df['image'].values\r\n",
    "label_list = df['label'].values\r\n",
    "label_list = paddle.to_tensor(label_list, dtype='int64')\r\n",
    "train_label_list = paddle.nn.functional.one_hot(label_list, num_classes=7)\r\n",
    "\r\n",
    "val_image_path_list = val_image_list['image'].values\r\n",
    "val_label_list = val_image_list['label'].values\r\n",
    "val_label_list = paddle.to_tensor(val_label_list, dtype='int64')\r\n",
    "val_label_list = paddle.nn.functional.one_hot(val_label_list, num_classes=7)\r\n",
    "\r\n",
    "# 定义数据预处理\r\n",
    "data_transforms = T.Compose([\r\n",
    "    T.Resize(size=(48, 48)),\r\n",
    "    T.RandomRotation(5),\r\n",
    "    # T.RandomCrop(224),\r\n",
    "    T.RandomHorizontalFlip(0.5),\r\n",
    "    T.RandomVerticalFlip(0.5),\r\n",
    "    T.Transpose(),    # HWC -> CHW   \r\n",
    "])\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 构建Dataset\r\n",
    "class MyDataset(paddle.io.Dataset):\r\n",
    "    \"\"\"\r\n",
    "    步骤一：继承paddle.io.Dataset类\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, train_img_list, val_img_list,train_label_list,val_label_list, mode='train'):\r\n",
    "        \"\"\"\r\n",
    "        步骤二：实现构造函数，定义数据读取方式，划分训练和测试数据集\r\n",
    "        \"\"\"\r\n",
    "        super(MyDataset, self).__init__()\r\n",
    "        self.img = []\r\n",
    "        self.label = []\r\n",
    "        # 借助pandas读csv的库\r\n",
    "        self.train_images = train_img_list\r\n",
    "        self.test_images = val_img_list\r\n",
    "        self.train_label = train_label_list\r\n",
    "        self.test_label = val_label_list\r\n",
    "        if mode == 'train':\r\n",
    "            # 读train_images的数据\r\n",
    "            for img,la in zip(self.train_images, self.train_label):\r\n",
    "                self.img.append('data/data100817/Datawhale/train/'+img)\r\n",
    "                self.label.append(la)\r\n",
    "        else:\r\n",
    "            # 读test_images的数据\r\n",
    "            for img,la in zip(self.test_images, self.test_label):\r\n",
    "                self.img.append('data/data100817/Datawhale/train/'+img)\r\n",
    "                self.label.append(la)\r\n",
    "\r\n",
    "    def load_img(self, image_path):\r\n",
    "        # 实际使用时使用Pillow相关库进行图片读取即可，这里我们对数据先做个模拟\r\n",
    "        image = Image.open(image_path)\r\n",
    "        image = np.asarray(image)\r\n",
    "        image = image.astype(np.float32) / 255.\r\n",
    "        return image\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        \"\"\"\r\n",
    "        步骤三：实现__getitem__方法，定义指定index时如何获取数据，并返回单条数据（训练数据，对应的标签）\r\n",
    "        \"\"\"\r\n",
    "        image = self.load_img(self.img[index])\r\n",
    "        label = self.label[index]\r\n",
    "        # label = paddle.to_tensor(label)\r\n",
    "        \r\n",
    "        return data_transforms(image), paddle.nn.functional.label_smooth(label)\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        \"\"\"\r\n",
    "        步骤四：实现__len__方法，返回数据集总数目\r\n",
    "        \"\"\"\r\n",
    "        return len(self.img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_loader\r\n",
    "train_dataset = MyDataset(train_img_list=train_image_path_list, val_img_list=val_image_path_list, train_label_list=train_label_list, val_label_list=val_label_list, mode='train')\r\n",
    "train_loader = paddle.io.DataLoader(train_dataset, places=paddle.CPUPlace(), batch_size=196, shuffle=True, num_workers=0)\r\n",
    "\r\n",
    "#val_loader\r\n",
    "val_dataset = MyDataset(train_img_list=train_image_path_list, val_img_list=val_image_path_list, train_label_list=train_label_list, val_label_list=val_label_list, mode='test')\r\n",
    "val_loader = paddle.io.DataLoader(val_dataset, places=paddle.CPUPlace(), batch_size=196, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 数据读取测试\r\n",
    "\r\n",
    "print('=============train dataset=============')\r\n",
    "for image, label in train_dataset:\r\n",
    "    print('image shape: {}, label: {}'.format(image.shape, label))\r\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from work.se_resnext import SE_ResNeXt50_vd_32x4d\r\n",
    "# from work.res2net import Res2Net50_vd_26w_4s\r\n",
    "from paddle.vision.ops import DeformConv2D\r\n",
    "# 模型封装\r\n",
    "model_res = SE_ResNeXt50_vd_32x4d(class_dim=7)\r\n",
    "model = paddle.Model(model_res)\r\n",
    "\r\n",
    "# 定义优化器\r\n",
    "optim = paddle.optimizer.Adam(learning_rate=3e-4, parameters=model.parameters())\r\n",
    "\r\n",
    "# 配置模型\r\n",
    "model.prepare(\r\n",
    "    optim,\r\n",
    "    paddle.nn.CrossEntropyLoss(soft_label=True),\r\n",
    "    Accuracy()\r\n",
    "    )\r\n",
    "\r\n",
    "# model.load('work/SE_ResNeXt50_vd_32x4d_pretrained.pdparams',skip_mismatch=True)\r\n",
    "\r\n",
    "# 模型训练与评估\r\n",
    "model.fit(train_loader,\r\n",
    "        val_loader,\r\n",
    "        log_freq=1,\r\n",
    "        epochs=16,\r\n",
    "        verbose=1,\r\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save('Hapi_MyCNN3', False)  # save for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, time\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import paddle\r\n",
    "import pandas as pd\r\n",
    "from PIL import Image\r\n",
    "import numpy as np\r\n",
    "# import patta as tta\r\n",
    "\r\n",
    "\r\n",
    "use_gpu = False\r\n",
    "model_file_path=\"Hapi_MyCNN3\"\r\n",
    "paddle.set_device('gpu:0') if use_gpu else paddle.set_device('cpu')\r\n",
    "model = paddle.jit.load(model_file_path)\r\n",
    "\r\n",
    "# model = tta.ClassificationTTAWrapper(model, tta.aliases.ten_crop_transform(48,48))\r\n",
    "model.eval() #训练模式\r\n",
    "\r\n",
    "def load_image(img_path):\r\n",
    "    '''\r\n",
    "    预测图片预处理\r\n",
    "    '''\r\n",
    "    img = Image.open(img_path)\r\n",
    "    \r\n",
    "    #resize\r\n",
    "    # img = img.resize((224, 224), Image.BILINEAR) #Image.BILINEAR双线性插值\r\n",
    "    img = np.array(img).astype('float32')\r\n",
    "\r\n",
    "    # HWC to CHW \r\n",
    "    # img = img.transpose((2, 0, 1))\r\n",
    "    \r\n",
    "    #Normalize\r\n",
    "    img = img / 255         #像素值归一化\r\n",
    "  \r\n",
    "    return img\r\n",
    "\r\n",
    "def infer_img(path, model):\r\n",
    "    '''\r\n",
    "    模型预测\r\n",
    "    '''\r\n",
    "    #对预测图片进行预处理\r\n",
    "    infer_imgs = []\r\n",
    "    infer_imgs.append(load_image(path))\r\n",
    "    infer_imgs = np.array(infer_imgs)\r\n",
    "    label_list = {0:'angry', 1:'disgusted', 2:'fearful' , 3:'happy', 4:'neutral', 5:'sad', 6:'surprised'}\r\n",
    "    #\r\n",
    "    label_pre = []\r\n",
    "    for i in range(len(infer_imgs)):\r\n",
    "        data = infer_imgs[i]\r\n",
    "        dy_x_data = np.array(data).astype('float32')\r\n",
    "        dy_x_data = dy_x_data[np.newaxis,np.newaxis, :,:]\r\n",
    "        img = paddle.to_tensor(dy_x_data)\r\n",
    "        out = model(img)\r\n",
    "        lab = np.argmax(out.numpy())  #argmax():返回最大数的索引\r\n",
    "        \r\n",
    "        label_pre.append(label_list[lab])\r\n",
    "        \r\n",
    "    return label_pre\r\n",
    "\r\n",
    "img_list = os.listdir('data/data100817/Datawhale/test')\r\n",
    "img_list.sort(key=lambda x: int(x[:-4]))\r\n",
    "\r\n",
    "pre_list = []\r\n",
    "for i in range(len(img_list)):\r\n",
    "    pre_list.append(infer_img(path='data/data100817/Datawhale/test/' + img_list[i], model=model)[0])\r\n",
    "\r\n",
    "img = pd.DataFrame(img_list)\r\n",
    "img = img.rename(columns = {0:\"name\"})\r\n",
    "img['label'] = pre_list\r\n",
    "\r\n",
    "img.to_csv('submitrenlian3.csv', index=False)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 总结\n",
    "\n",
    "\n",
    "首先这是一个基线，用来快速试错，事实证明，这个不好用。所以下一期计划魔改一下LeNet5来做这个比赛基线，因为数据集是48 * 48 * 1，通道数为1，并且图像的尺寸也不大。再改一下损失函数，应该能够取得一个差不多的成绩吧。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
