{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 讯飞叶菜病虫害图像识别挑战赛\n",
    "\n",
    "一、赛事背景\n",
    "农作物病虫害严重制约着农业生产，因为农作物病虫害种类多、密度大，极易造成农作物大量减产。同时由于传统人眼识别病虫害的方法速度较慢、准确度较低，会导致农药的滥用，破坏自然环境。如今随着精准农业和智慧农业概念的兴起和发展，利用信息技术辅助农业生产，实现对农作物病虫害的智能识别和检测，以减少不必要的农药喷施，对保护生态系统均衡，保障农作物安全生产，提高农作物的质量方面，有着十分重要的促进作用。\n",
    "\n",
    "二、赛事任务\n",
    "最为有效的病虫害识别方法是图片识别，本次大赛提供了大量农民在田间地头拍摄的叶菜的病虫害图片，参赛选手需基于提供的样本构建模型，实现叶菜的病虫害图像识别，即为图片分类。\n",
    "\n",
    "初赛一阶段：6月21日到8月18日。\n",
    "\n",
    "初赛二阶段：8月19日到8月20日。系统将在8月19日00：00更换测试数据，参赛队伍需要再次下载数据\n",
    "\n",
    "三、评审规则\n",
    "1.数据说明\n",
    "本次比赛为参赛选手提供了叶菜的病虫害图像数据：包括图像及其所属病虫害标签。数据主体为农民在不同环境条件下拍摄的叶菜农作物图像，每张图像的主体突出度，背景复杂程度、光照条件，图像清晰度均存在一定差别。选手可自己搜集训练数据提升模型识别效果，需要将搜集的图片上传至官方云盘。图片已按类别放在不同文件夹内，文件夹名称即为图片的category_id。\n",
    "\n",
    "1：用药不当\n",
    "\n",
    "2：疫病\n",
    "\n",
    "3：炭疽病\n",
    "\n",
    "\n",
    "四、数据展示\n",
    "\n",
    "<br></br>\n",
    "\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/5a63e693645242cf973fc3809801c748255ffc4a210441e8811b8ab5343236fe\" width = \"300\" height = \"400\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/59241090c5f149fdb4d4dc4457e84dd7b99f233022be4fa6afbab30adb3fd6a3\" width = \"300\" height = \"400\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/20750ae0ad8748318b6f63d6d159ab731d7fda2ab15f44db9047e0691e0f4cae\" width = \"300\" height = \"400\">\n",
    "\n",
    "\n",
    "<br></br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 基线分数\n",
    "\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/4a723ff0476b432d98add5c0d144b82ed1830395b01e47ceb3376e4660fc7573)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 数据集解压\r\n",
    "\r\n",
    "!cd 'data/data100276' && unzip -q bingchonghai1.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 数据EDA\n",
    "\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/f3466620cf5340689a43128c4e2b74daa90191c8874f47348770a32ccd5bc1e2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 数据预处理及读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normMean = [0.4915503, 0.52611285, 0.38987514]\n",
      "normStd = [0.22698687, 0.21348892, 0.23523445]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "import cv2\r\n",
    "import os\r\n",
    " \r\n",
    "img_h, img_w = 224, 224   #根据自己数据集适当调整，影响不大\r\n",
    "means, stdevs = [], []\r\n",
    "img_list = []\r\n",
    " \r\n",
    "imgs_path = 'data/data100276/bingchonghai1/test'\r\n",
    "imgs_path_list = os.listdir(imgs_path)\r\n",
    " \r\n",
    "len_ = len(imgs_path_list)\r\n",
    "i = 0\r\n",
    "for item in imgs_path_list:\r\n",
    "    img = cv2.imread(os.path.join(imgs_path,item))\r\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)\r\n",
    "    img = cv2.resize(img,(img_w,img_h))\r\n",
    "    # print('****************', item)\r\n",
    "    img = img[:, :, :, np.newaxis]\r\n",
    "    img_list.append(img)\r\n",
    "    i += 1\r\n",
    "    # print(i,'/',len_)\r\n",
    "\r\n",
    "imgs_path = 'data/data100276/bingchonghai1/test'\r\n",
    "imgs_path_list = os.listdir(imgs_path)\r\n",
    " \r\n",
    "len_ = len(imgs_path_list)\r\n",
    "i = 0\r\n",
    "for item in imgs_path_list:\r\n",
    "    img = cv2.imread(os.path.join(imgs_path,item))\r\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)\r\n",
    "    img = cv2.resize(img,(img_w,img_h))\r\n",
    "    # print('++++++++++++++',item)\r\n",
    "    img = img[:, :, :, np.newaxis]\r\n",
    "    img_list.append(img)\r\n",
    "    i += 1\r\n",
    "    # print(i,'/',len_)\r\n",
    "\r\n",
    "# print(len(img_list))\r\n",
    "\r\n",
    "imgs = np.concatenate(img_list, axis=3)\r\n",
    "imgs = imgs.astype(np.float32) / 255.\r\n",
    " \r\n",
    "for i in range(3):\r\n",
    "    pixels = imgs[:, :, i, :].ravel()  # 拉成一行\r\n",
    "    means.append(np.mean(pixels))\r\n",
    "    stdevs.append(np.std(pixels))\r\n",
    " \r\n",
    "# BGR --> RGB ， CV读取的需要转换，PIL读取的不用转换\r\n",
    "means.reverse()\r\n",
    "stdevs.reverse()\r\n",
    " \r\n",
    "print(\"normMean = {}\".format(means))\r\n",
    "print(\"normStd = {}\".format(stdevs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 导入所需要的库\r\n",
    "from sklearn.utils import shuffle\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from PIL import Image\r\n",
    "\r\n",
    "import paddle\r\n",
    "import paddle.nn as nn\r\n",
    "from paddle.io import Dataset\r\n",
    "import paddle.vision.transforms as T\r\n",
    "import paddle.nn.functional as F\r\n",
    "from paddle.metric import Accuracy\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")\r\n",
    "\r\n",
    "# 读取数据\r\n",
    "train_images = pd.read_csv('data/data100276/bingchonghai1/train.csv')\r\n",
    "train_images = shuffle(train_images)\r\n",
    "# 划分训练集和校验集\r\n",
    "all_size = len(train_images)\r\n",
    "# print(all_size)\r\n",
    "train_size = int(all_size * 0.55)\r\n",
    "train_image_list = train_images[:train_size]\r\n",
    "val_image_list = train_images[train_size:]\r\n",
    "df = train_image_list\r\n",
    "df = shuffle(df)\r\n",
    "train_image_path_list = df['image'].values\r\n",
    "label_list = df['label'].values\r\n",
    "label_list = paddle.to_tensor(label_list, dtype='int64')\r\n",
    "train_label_list = paddle.nn.functional.one_hot(label_list, num_classes=3)\r\n",
    "\r\n",
    "val_image_path_list = val_image_list['image'].values\r\n",
    "val_label_list = val_image_list['label'].values\r\n",
    "val_label_list = paddle.to_tensor(val_label_list, dtype='int64')\r\n",
    "val_label_list = paddle.nn.functional.one_hot(val_label_list, num_classes=3)\r\n",
    "\r\n",
    "# 定义数据预处理\r\n",
    "data_transforms = T.Compose([\r\n",
    "    T.Resize(size=(224, 224)),\r\n",
    "    T.RandomRotation(45),\r\n",
    "    T.RandomCrop(224),\r\n",
    "    T.RandomHorizontalFlip(0.5),\r\n",
    "    T.RandomVerticalFlip(0.5),\r\n",
    "    T.Transpose(),    # HWC -> CHW\r\n",
    "    T.Normalize(\r\n",
    "        mean=[0.4969582, 0.52626157, 0.3855794],        # 归一化\r\n",
    "        std=[0.22970483, 0.2152645, 0.23676889],\r\n",
    "        to_rgb=True)    \r\n",
    "])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 构建Dataset\r\n",
    "class MyDataset(paddle.io.Dataset):\r\n",
    "    \"\"\"\r\n",
    "    步骤一：继承paddle.io.Dataset类\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, train_img_list, val_img_list,train_label_list,val_label_list, mode='train'):\r\n",
    "        \"\"\"\r\n",
    "        步骤二：实现构造函数，定义数据读取方式，划分训练和测试数据集\r\n",
    "        \"\"\"\r\n",
    "        super(MyDataset, self).__init__()\r\n",
    "        self.img = []\r\n",
    "        self.label = []\r\n",
    "        # 借助pandas读csv的库\r\n",
    "        self.train_images = train_img_list\r\n",
    "        self.test_images = val_img_list\r\n",
    "        self.train_label = train_label_list\r\n",
    "        self.test_label = val_label_list\r\n",
    "        if mode == 'train':\r\n",
    "            # 读train_images的数据\r\n",
    "            for img,la in zip(self.train_images, self.train_label):\r\n",
    "                self.img.append('data/data100276/bingchonghai1/train/'+img)\r\n",
    "                self.label.append(la)\r\n",
    "        else:\r\n",
    "            # 读test_images的数据\r\n",
    "            for img,la in zip(self.test_images, self.test_label):\r\n",
    "                self.img.append('data/data100276/bingchonghai1/train/'+img)\r\n",
    "                self.label.append(la)\r\n",
    "\r\n",
    "    def load_img(self, image_path):\r\n",
    "        # 实际使用时使用Pillow相关库进行图片读取即可，这里我们对数据先做个模拟\r\n",
    "        image = Image.open(image_path).convert('RGB')\r\n",
    "        image = np.asarray(image)\r\n",
    "        image = image.astype(np.float32) / 255.\r\n",
    "        return image\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        \"\"\"\r\n",
    "        步骤三：实现__getitem__方法，定义指定index时如何获取数据，并返回单条数据（训练数据，对应的标签）\r\n",
    "        \"\"\"\r\n",
    "        image = self.load_img(self.img[index])\r\n",
    "        label = self.label[index]\r\n",
    "        # label = paddle.to_tensor(label)\r\n",
    "        \r\n",
    "        return data_transforms(image), paddle.nn.functional.label_smooth(label)\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        \"\"\"\r\n",
    "        步骤四：实现__len__方法，返回数据集总数目\r\n",
    "        \"\"\"\r\n",
    "        return len(self.img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_loader\r\n",
    "train_dataset = MyDataset(train_img_list=train_image_path_list, val_img_list=val_image_path_list, train_label_list=train_label_list, val_label_list=val_label_list, mode='train')\r\n",
    "train_loader = paddle.io.DataLoader(train_dataset, places=paddle.CPUPlace(), batch_size=196, shuffle=True, num_workers=0)\r\n",
    "\r\n",
    "#val_loader\r\n",
    "val_dataset = MyDataset(train_img_list=train_image_path_list, val_img_list=val_image_path_list, train_label_list=train_label_list, val_label_list=val_label_list, mode='test')\r\n",
    "val_loader = paddle.io.DataLoader(val_dataset, places=paddle.CPUPlace(), batch_size=196, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 模型训练及保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/6\n",
      "step 4/4 [==============================] - loss: 0.5471 - acc: 0.4340 - 38s/step          \n",
      "Eval begin...\n",
      "step 3/3 [==============================] - loss: 0.5401 - acc: 0.4809 - 43s/step         \n",
      "Eval samples: 497\n",
      "Epoch 2/6\n",
      "step 4/4 [==============================] - loss: 0.4562 - acc: 0.5644 - 42s/step          \n",
      "Eval begin...\n",
      "step 3/3 [==============================] - loss: 0.4943 - acc: 0.4809 - 44s/step         \n",
      "Eval samples: 497\n",
      "Epoch 3/6\n",
      "step 4/4 [==============================] - loss: 0.4477 - acc: 0.6155 - 41s/step          \n",
      "Eval begin...\n",
      "step 3/3 [==============================] - loss: 0.5476 - acc: 0.4024 - 50s/step          \n",
      "Eval samples: 497\n",
      "Epoch 4/6\n",
      "step 4/4 [==============================] - loss: 0.3988 - acc: 0.5677 - 38s/step          \n",
      "Eval begin...\n",
      "step 3/3 [==============================] - loss: 0.5709 - acc: 0.3843 - 41s/step         \n",
      "Eval samples: 497\n",
      "Epoch 5/6\n",
      "step 4/4 [==============================] - loss: 0.4324 - acc: 0.6419 - 39s/step          \n",
      "Eval begin...\n",
      "step 3/3 [==============================] - loss: 0.7259 - acc: 0.4225 - 41s/step         \n",
      "Eval samples: 497\n",
      "Epoch 6/6\n",
      "step 4/4 [==============================] - loss: 0.3930 - acc: 0.5693 - 37s/step          \n",
      "Eval begin...\n",
      "step 3/3 [==============================] - loss: 0.4594 - acc: 0.4266 - 41s/step         \n",
      "Eval samples: 497\n"
     ]
    }
   ],
   "source": [
    "# from work.se_resnext import SE_ResNeXt50_vd_32x4d\r\n",
    "from work.res2net import Res2Net50_vd_26w_4s\r\n",
    "\r\n",
    "# 模型封装\r\n",
    "model_res = Res2Net50_vd_26w_4s(class_dim=3)\r\n",
    "model = paddle.Model(model_res)\r\n",
    "\r\n",
    "# 定义优化器\r\n",
    "optim = paddle.optimizer.Adam(learning_rate=3e-4, parameters=model.parameters())\r\n",
    "\r\n",
    "# 配置模型\r\n",
    "model.prepare(\r\n",
    "    optim,\r\n",
    "    paddle.nn.CrossEntropyLoss(soft_label=True),\r\n",
    "    Accuracy()\r\n",
    "    )\r\n",
    "\r\n",
    "model.load('work/Res2Net50_vd_26w_4s_pretrained.pdparams',skip_mismatch=True)\r\n",
    "\r\n",
    "save_dir = '/home/aistudio/work'\r\n",
    "# 模型训练与评估\r\n",
    "model.fit(train_loader,\r\n",
    "        val_loader,\r\n",
    "        log_freq=1,\r\n",
    "        epochs=6,\r\n",
    "        verbose=1,\r\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 保存模型参数\r\n",
    "# model.save('Hapi_MyCNN')  # save for training\r\n",
    "model.save('Hapi_MyCNN1_res2', False)  # save for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 模型预测\n",
    "\n",
    "\n",
    "* **模型融合与TTA**\n",
    "\n",
    "\n",
    "test time augmentation，TTA\n",
    "\n",
    "可将准确率提高若干个百分点，它就是测试时增强（test time augmentation, TTA）。这里会为原始图像造出多个不同版本，包括不同区域裁剪和更改缩放程度等，并将它们输入到模型中；然后对多个版本进行计算得到平均输出，作为图像的最终输出分数。有作弊的嫌疑。这种技术很有效，因为原始图像显示的区域可能会缺少一些重要特征，在模型中输入图像的多个版本并取平均值，能解决上述问题。\n",
    "\n",
    "\n",
    "模型融合\n",
    "\n",
    "\n",
    "我可能是搞了一个比较邪的模型融合，哈哈哈，分别是单独训练，在预测的时候加权融合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, time\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import paddle\r\n",
    "from PIL import Image\r\n",
    "import numpy as np\r\n",
    "import patta as tta\r\n",
    "\r\n",
    "\r\n",
    "use_gpu = True\r\n",
    "model_file_path=\"Hapi_MyCNN1_res2\"\r\n",
    "paddle.set_device('gpu:0') if use_gpu else paddle.set_device('cpu')\r\n",
    "model = paddle.jit.load(model_file_path)\r\n",
    "\r\n",
    "model = tta.ClassificationTTAWrapper(model, tta.aliases.ten_crop_transform(224,224))\r\n",
    "model.eval() #训练模式\r\n",
    "\r\n",
    "def load_image(img_path):\r\n",
    "    '''\r\n",
    "    预测图片预处理\r\n",
    "    '''\r\n",
    "    img = Image.open(img_path).convert('RGB')\r\n",
    "    \r\n",
    "    #resize\r\n",
    "    img = img.resize((224, 224), Image.BILINEAR) #Image.BILINEAR双线性插值\r\n",
    "    img = np.array(img).astype('float32')\r\n",
    "\r\n",
    "    # HWC to CHW \r\n",
    "    img = img.transpose((2, 0, 1))\r\n",
    "    \r\n",
    "    #Normalize\r\n",
    "    img = img / 255         #像素值归一化\r\n",
    "    # print(img)\r\n",
    "    mean = [0.4494708, 0.45852903, 0.29217097]   \r\n",
    "    std = [0.2794664, 0.2744329, 0.2591805]\r\n",
    "    img[0] = (img[0] - mean[0]) / std[0]\r\n",
    "    img[1] = (img[1] - mean[1]) / std[1]\r\n",
    "    img[2] = (img[2] - mean[2]) / std[2]\r\n",
    "    \r\n",
    "    return img\r\n",
    "\r\n",
    "def infer_img(path, model):\r\n",
    "    '''\r\n",
    "    模型预测\r\n",
    "    '''\r\n",
    "    \r\n",
    "\r\n",
    "    #对预测图片进行预处理\r\n",
    "    infer_imgs = []\r\n",
    "    infer_imgs.append(load_image(path))\r\n",
    "    infer_imgs = np.array(infer_imgs)\r\n",
    "    label_list = ['0:優良', '1:良', '2:加工品', '3:規格外']\r\n",
    "    label_pre = []\r\n",
    "    for i in range(len(infer_imgs)):\r\n",
    "        data = infer_imgs[i]\r\n",
    "        dy_x_data = np.array(data).astype('float32')\r\n",
    "        dy_x_data = dy_x_data[np.newaxis,:, : ,:]\r\n",
    "        img = paddle.to_tensor(dy_x_data)\r\n",
    "        out = model(img)\r\n",
    "        # print(out[0])\r\n",
    "        # print(paddle.nn.functional.softmax(out)[0]) # 若模型中已经包含softmax则不用此行代码。\r\n",
    "\r\n",
    "        lab = np.argmax(out.numpy())  #argmax():返回最大数的索引\r\n",
    "        label_pre.append(int(lab)+1)\r\n",
    "       \r\n",
    "    return label_pre\r\n",
    "\r\n",
    "img_list = os.listdir('data/data100276/bingchonghai1/test')\r\n",
    "\r\n",
    "pre_list = []\r\n",
    "\r\n",
    "for i in range(len(img_list)):\r\n",
    "    pre_list.append(infer_img(path='data/data100276/bingchonghai1/test/' + img_list[i], model=model)[0])\r\n",
    "\r\n",
    "img = pd.DataFrame(img_list)\r\n",
    "img = img.rename(columns = {0:\"image_id\"})\r\n",
    "img['category_id'] = pre_list\r\n",
    "\r\n",
    "img.to_csv('submitbingchong.csv', index=False)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 总结\n",
    "\n",
    "\n",
    "\n",
    "大家可以看到，我们的基线分数并不高，所以这很可能是一个失败的基线，模型预测的效果并不好，这个的难点就是细粒度分类，每个类别之间的区分度不是很大，所以仅仅是用这种方式还不够，大家还可以尝试一下元学习等方法，或者是不使用最后的softmax进行分类，使用距离进行类别判断。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
